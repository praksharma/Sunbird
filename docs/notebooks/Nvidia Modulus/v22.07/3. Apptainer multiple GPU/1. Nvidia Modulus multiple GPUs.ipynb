{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcc01abf-f3a5-457d-90cd-4a25c6ae8f23",
   "metadata": {},
   "source": [
    "# Running jobs using multiple GPUs\n",
    "## Running Nvidia Modulus on Sunbird\n",
    "The Apptainer image is located at\n",
    "\n",
    "```sh\n",
    "[s.1915438@sl1 ~]$ module display modulus/22.07\n",
    "-------------------------------------------------------------------\n",
    "/apps/local/modules/tools/modulus/22.07:\n",
    "\n",
    "module\t\t load apptainer/1.0.3 \n",
    "module-whatis\t add NVIDIA Modulus to PATH environment variables \n",
    "setenv\t\t MODULUS_IMG /apps/local/tools/modulus/22.07/modulus_apptainer/modulus.img \n",
    "-------------------------------------------------------------------\n",
    "```\n",
    "\n",
    "The `setenv` tells us that the environment variable `MODULUS_IMG` points to `/apps/local/tools/modulus/22.07/modulus_apptainer/modulus.img`. So, we can run the Apptainer image with bypassed default volume binds and environments varible exports.\n",
    "\n",
    "```sh\n",
    "apptainer shell --nv --contain --cleanenv --bind \"$(pwd)\":/data,/tmp:/tmp $MODULUS_IMG\n",
    "```\n",
    "\n",
    "This works perfectly fine with 1 GPU. But for multiple GPU we need to use the `mpirun` [(link)](https://docs.nvidia.com/deeplearning/modulus/user_guide/features/performance.html?highlight=mpirun#running-jobs-using-multiple-gpus).\n",
    "\n",
    "The command to use the `mpirun` is `mpirun -np #GPUs`. For example, with 2 GPUs\n",
    "\n",
    "```sh\n",
    "Apptainer> mpirun -np 2 python ldc/ldc_2d.py\n",
    "Initialized process 0 of 2 using method \"openmpi\". Device set to cuda:0\n",
    "Initialized process 1 of 2 using method \"openmpi\". Device set to cuda:1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f9c87e-20c2-41ec-905b-7ae4eecbba7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Problem with `mpirun` (SKIP IF NEEDED)\n",
    "We need to export `$CUDA_VISIBLE_DEVICES` inside the Apptainer image otherwise if $n$ GPUs are allocated than `mpirun` will use first $n$ GPUs. For example, if I was allocated GPU number 2 and 3.\n",
    "\n",
    "```sh\n",
    "[s.1915438@scs2043 examples]$ echo $CUDA_VISIBLE_DEVICES\n",
    "2,3\n",
    "[s.1915438@scs2043 ~]$ nvidia-smi\n",
    "Mon Sep 12 01:20:59 2022\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  NVIDIA A100-PCI...  On   | 00000000:27:00.0 Off |                    0 |\n",
    "| N/A   53C    P0   231W / 250W |   5487MiB / 40960MiB |     57%      Default |\n",
    "|                               |                      |             Disabled |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   1  NVIDIA A100-PCI...  On   | 00000000:28:00.0 Off |                    0 |\n",
    "| N/A   56C    P0    94W / 250W |   5487MiB / 40960MiB |     71%      Default |\n",
    "|                               |                      |             Disabled |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   2  NVIDIA A100-PCI...  On   | 00000000:43:00.0 Off |                    0 |\n",
    "| N/A   45C    P0    47W / 250W |      2MiB / 40960MiB |      0%      Default |\n",
    "|                               |                      |             Disabled |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   3  NVIDIA A100-PCI...  On   | 00000000:44:00.0 Off |                    0 |\n",
    "| N/A   45C    P0    45W / 250W |      2MiB / 40960MiB |      0%      Default |\n",
    "|                               |                      |             Disabled |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   4  NVIDIA A100-PCI...  On   | 00000000:A3:00.0 Off |                    0 |\n",
    "| N/A   40C    P0    47W / 250W |      2MiB / 40960MiB |      0%      Default |\n",
    "|                               |                      |             Disabled |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   5  NVIDIA A100-PCI...  On   | 00000000:A4:00.0 Off |                    0 |\n",
    "| N/A   40C    P0    47W / 250W |      2MiB / 40960MiB |      0%      Default |\n",
    "|                               |                      |             Disabled |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   6  NVIDIA A100-PCI...  On   | 00000000:C3:00.0 Off |                    0 |\n",
    "| N/A   39C    P0    48W / 250W |      2MiB / 40960MiB |      0%      Default |\n",
    "|                               |                      |             Disabled |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   7  NVIDIA A100-PCI...  On   | 00000000:C4:00.0 Off |                    0 |\n",
    "| N/A   39C    P0    46W / 250W |      2MiB / 40960MiB |      0%      Default |\n",
    "|                               |                      |             Disabled |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "\n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|    0   N/A  N/A      2282      C   python                           5485MiB |\n",
    "|    1   N/A  N/A      2283      C   python                           5485MiB |\n",
    "+-----------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8ecee-bab7-43a6-ad46-8f60af4dabd8",
   "metadata": {},
   "source": [
    "# Use `mpirun`\n",
    "\n",
    "We need to export `$CUDA_VISIBLE_DEVICES` to properly use the right GPUs.\n",
    "\n",
    "```sh\n",
    "[s.1915438@scs2043 ~]$ nvidia-smi -i 2,3\n",
    "Mon Sep 12 01:29:42 2022\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   2  NVIDIA A100-PCI...  On   | 00000000:43:00.0 Off |                    0 |\n",
    "| N/A   63C    P0   112W / 250W |   5487MiB / 40960MiB |     66%      Default |\n",
    "|                               |                      |             Disabled |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   3  NVIDIA A100-PCI...  On   | 00000000:44:00.0 Off |                    0 |\n",
    "| N/A   62C    P0   206W / 250W |   5487MiB / 40960MiB |     82%      Default |\n",
    "|                               |                      |             Disabled |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "\n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|    2   N/A  N/A      3255      C   python                           5485MiB |\n",
    "|    3   N/A  N/A      3256      C   python                           5485MiB |\n",
    "+-----------------------------------------------------------------------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29a70ae-cc26-489e-933c-fb5e9411bf30",
   "metadata": {},
   "source": [
    "# Best Practice\n",
    "* Allocate the resources\n",
    "\n",
    "\n",
    "```sh\n",
    "salloc --nodes=1 --account=scw1901 --partition=accel_ai --gres=gpu:2 --nodelist=scs2043\n",
    "```\n",
    "\n",
    "* Switch to the compute node\n",
    "```sh\n",
    "srun --pty bash\n",
    "```\n",
    "\n",
    "* Load NVIDIA Modulus 22.07\n",
    "\n",
    "```sh\n",
    "module load modulus/22.07\n",
    "```\n",
    "\n",
    "* Start the container with [--env](https://apptainer.org/user-docs/master/environment_and_metadata.html#env-option) for CUDA devices\n",
    "```sh\n",
    "apptainer shell --nv --contain --cleanenv --bind \"$(pwd)\":/data,/tmp:/tmp --env CUDA_VISIBLE_DEVICES=$CUDA_VISIBLE_DEVICES $MODULUS_IMG\n",
    "```\n",
    "\n",
    "One can check if the `$CUDA_VISIBLE_DEVICES` was successfully imported.\n",
    "```sh\n",
    "Apptainer> env | grep CUDA_VISIBLE_DEVICES\n",
    "CUDA_VISIBLE_DEVICES=2,3\n",
    "```\n",
    "\n",
    "* Running an example.\n",
    "```sh\n",
    "Apptainer> cd /data/ldc/\n",
    "Apptainer> ls\n",
    "conf  conf_zeroEq  ldc_2d.py  ldc_2d_importance_sampling.py  ldc_2d_zeroEq.py  openfoam\n",
    "Apptainer> mpirun -np 2 python ldc_2d.py \n",
    "Initialized process 0 of 2 using method \"openmpi\". Device set to cuda:0\n",
    "Initialized process 1 of 2 using method \"openmpi\". Device set to cuda:1\n",
    "[01:28:14] - attempting to restore from: outputs/ldc_2d\n",
    "[01:28:14] - optimizer checkpoint not found\n",
    "[01:28:14] - model flow_network.pth not found\n",
    "[01:28:14] - attempting to restore from: outputs/ldc_2d\n",
    "[01:28:14] - optimizer checkpoint not found\n",
    "[01:28:14] - model flow_network.pth not found\n",
    "[01:28:24] - [step:          0] record constraint batch time:  3.484e-01s\n",
    "[01:28:40] - [step:          0] record validators time:  1.606e+01s\n",
    "[01:28:52] - [step:          0] record inferencers time:  1.134e+01s\n",
    "[01:28:52] - [step:          0] saved checkpoint to outputs/ldc_2d\n",
    "[01:28:52] - [step:          0] loss:  5.037e-02\n",
    "[01:28:52] - Reducer buckets have been rebuilt in this iteration.\n",
    "[01:28:52] - Reducer buckets have been rebuilt in this iteration.\n",
    "[01:28:52] - Reducer buckets have been rebuilt in this iteration.\n",
    "[01:28:52] - Reducer buckets have been rebuilt in this iteration.\n",
    "[01:28:52] - Reducer buckets have been rebuilt in this iteration.\n",
    "[01:28:52] - Reducer buckets have been rebuilt in this iteration.\n",
    "[01:28:54] - Attempting cuda graph building, this may take a bit...\n",
    "[01:28:54] - Attempting cuda graph building, this may take a bit...\n",
    "[01:29:00] - [step:        100] loss:  7.916e-03, time/iteration:  8.412e+01 ms\n",
    "[01:29:07] - [step:        200] loss:  5.416e-03, time/iteration:  6.566e+01 ms\n",
    "[01:29:14] - [step:        300] loss:  4.992e-03, time/iteration:  6.685e+01 ms\n",
    "[01:29:20] - [step:        400] loss:  3.430e-03, time/iteration:  6.476e+01 ms\n",
    "[01:29:28] - [step:        500] loss:  2.418e-03, time/iteration:  8.192e+01 ms\n",
    "[01:29:35] - [step:        600] loss:  2.150e-03, time/iteration:  6.622e+01 ms\n",
    "[01:29:41] - [step:        700] loss:  1.699e-03, time/iteration:  6.515e+01 ms\n",
    "```\n",
    "\n",
    "* The `nvidia-smi`'s output is as follows:\n",
    "\n",
    "```sh\n",
    "[s.1915438@sl1 ~]$ ssh scs2043\n",
    "Last login: Mon Sep 12 01:13:49 2022 from sl1\n",
    "[s.1915438@scs2043 ~]$ nvidia-smi -i 2,3\n",
    "Mon Sep 12 01:29:42 2022       \n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   2  NVIDIA A100-PCI...  On   | 00000000:43:00.0 Off |                    0 |\n",
    "| N/A   63C    P0   112W / 250W |   5487MiB / 40960MiB |     66%      Default |\n",
    "|                               |                      |             Disabled |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   3  NVIDIA A100-PCI...  On   | 00000000:44:00.0 Off |                    0 |\n",
    "| N/A   62C    P0   206W / 250W |   5487MiB / 40960MiB |     82%      Default |\n",
    "|                               |                      |             Disabled |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "                                                                               \n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|    2   N/A  N/A      3255      C   python                           5485MiB |\n",
    "|    3   N/A  N/A      3256      C   python                           5485MiB |\n",
    "+-----------------------------------------------------------------------------+\n",
    "[s.1915438@scs2043 ~]$ \n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
