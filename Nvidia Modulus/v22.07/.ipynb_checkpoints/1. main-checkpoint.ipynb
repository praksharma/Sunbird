{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96c176ba-9e6d-43c8-991d-f19969d69066",
   "metadata": {},
   "source": [
    "# Getting the base image ready to use\n",
    "\n",
    "## Installing Apptainer\n",
    "* Instructions: https://apptainer.org/docs/admin/main/installation.html\n",
    "* For Debian based OSes: https://apptainer.org/docs/admin/main/installation.html#install-debian-ubuntu-packages\n",
    "\n",
    "# Getting the Modulus source code\n",
    "Although NVIDIA provides the source code but it involves submodules for PySDF which we can't access. Submodulus are files or directories that is stored on another repopsitory which the user has access to. Alternatively, we can get the source code of Modulus from their Docker container. The syntax to copy files from Docker container to `pwd` is as follows:\n",
    "\n",
    "```sh\n",
    "docker cp container_id:FILE_PATH\n",
    "```\n",
    "\n",
    "But first we need to generate a `container ID`. For that, we can run the Docker image first. The list of all Docker images:\n",
    "\n",
    "```sh\n",
    "(base) hell@Dell-Precision-T7910:~/Desktop/PhD/PHD/Nvidia Modulus/Modulus v22.07$ docker image ls\n",
    "REPOSITORY               TAG                       IMAGE ID       CREATED        SIZE\n",
    "modulus                  22.07                     c3e6e5db96a5   7 weeks ago    16.7GB\n",
    "nvcr.io/nvidia/pytorch   22.07-py3                 b665b38ccc0e   8 weeks ago    14.8GB\n",
    "ubuntu                   focal-20220531            20fffa419e3a   2 months ago   72.8MB\n",
    "nvidia/cuda              11.0.3-base-ubuntu20.04   d134f267bb7a   3 months ago   122MB\n",
    "nvcr.io/nvidia/pytorch   22.05-py3                 e3470579ea78   3 months ago   14.6GB\n",
    "```\n",
    "\n",
    "Run the Modulus 22.07 image (use Tab completion).\n",
    "\n",
    "```sh\n",
    "docker run -it modulus:22.07\n",
    "```\n",
    "\n",
    "Locate the source code.\n",
    "\n",
    "```sh\n",
    "root@1f9c81c1bd54:/examples# ls /\n",
    "bin   dev  examples  lib    lib64   media  modulus  opt   rapids  run   srv  tmp  var\n",
    "boot  etc  home      lib32  libx32  mnt    nvidia   proc  root    sbin  sys  usr  workspace\n",
    "root@1f9c81c1bd54:/examples# ls /modulus/\n",
    "CONTRIBUTING.md  LICENSE.txt                        README.md              modulus\n",
    "Dockerfile       Modulus_overview.png               accompanying_licences  poetry.lock\n",
    "Dockerfile.user  NVIDIA-OptiX-SDK-7.0.0-linux64.sh  external               pyproject.toml\n",
    "root@1f9c81c1bd54:/examples# \n",
    "```\n",
    "\n",
    "Now note down the `container ID` using `docker container ls`.\n",
    "\n",
    "```sh\n",
    "base) hell@Dell-Precision-T7910:~/Desktop/PhD/PHD/Nvidia Modulus/Modulus v22.07$ docker container ls\n",
    "CONTAINER ID   IMAGE           COMMAND                  CREATED          STATUS          PORTS                NAMES\n",
    "1f9c81c1bd54   modulus:22.07   \"/opt/nvidia/nvidia_â€¦\"   13 seconds ago   Up 12 seconds   6006/tcp, 8888/tcp   recursing_hodgkin\n",
    "```\n",
    "\n",
    "Now navigate to a directory to store the Source code.\n",
    "\n",
    "```sh\n",
    "cd modulus_source\n",
    "docker cp 1f9c81c1bd54:/modulus/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbc01e0-9e09-45c8-b111-65e6747039c1",
   "metadata": {},
   "source": [
    "# The base image\n",
    "\n",
    "Now that we have the source code,  we can access the Docker recipe `Dockerfile`. The first two lines in the recipe tell us that the base image is a PyTorch image version 22.05 from [NVIDIA NGC](https://catalog.ngc.nvidia.com/) which is a pre-built Docker image repository. \n",
    "```sh\n",
    "ARG PYT_VER=22.05\n",
    "FROM nvcr.io/nvidia/pytorch:$PYT_VER-py3\n",
    "```\n",
    "\n",
    "Link to the base image: https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch\n",
    "\n",
    "We need to Pull the Docker image using `docker pull nvcr.io/nvidia/pytorch:22.05-py3`. Once the pullis complete, we can see the image in `docker image ls`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b853c-396d-4714-91ca-3a48d84f5ad4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Getting the base image ready\n",
    "Now we will [convert the Docker image to an Apptainer image](https://docs.sylabs.io/guides/2.6/user-guide/singularity_and_docker.html) as follows:\n",
    "```sh\n",
    "apptainer build pytorch.img docker://nvcr.io/nvidia/pytorch:22.05-py3\n",
    "```\n",
    "\n",
    "This is take some time (6.6 GB image). We can also use the Docker image directly into the Apptainer recipe but it would take long time to debug the script, as a single build will take at least 30 minutes. So, I thought this approach is much better because our aim is to obtain an error free Apptainer image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be502165-498c-48e1-aeaf-16d67210e68e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Converting the recipe\n",
    "[This](https://docs.sylabs.io/guides/2.6/user-guide/container_recipes.html) is an excellent manual for building an Apptainer image. If someone is used to Docker recipe, then [here](https://docs.sylabs.io/guides/3.5/user-guide/singularity_and_docker.html#singularity-definition-file-vs-dockerfile) is a conversion guide.\n",
    "\n",
    "Now let us write the recipe. One can always refer to [this](https://apptainer.org/docs/user/1.0/definition_files.html) manual for more details.\n",
    "## Header\n",
    "It tells Apptainer about the base operating system that it should use to build the container.\n",
    "\n",
    "```sh\n",
    "Bootstrap: localimage\n",
    "From: pytorch22.05.img\n",
    "Stage: build\n",
    "```\n",
    "\n",
    "Stages are optional.\n",
    "\n",
    "## Sections\n",
    "\n",
    "The order of individual sections deosn't matter.\n",
    "\n",
    "* Runtime: when we use the image\n",
    "* Build: when we are building the container\n",
    "\n",
    "### Export environment variables\n",
    "\n",
    "For the Docker recipe filter all the commands starting with `ENV` and add in the `%environment` section.\n",
    "\n",
    "```sh\n",
    "# export environment variables for runtime not the build\n",
    "%environment\n",
    "\t# Specify poetry version\n",
    "\texport POETRY_VERSION=1.1.13\n",
    "\texport LD_LIBRARY_PATH=\"/modulus/external/lib:${LD_LIBRARY_PATH}\" \\\n",
    "    \tNVIDIA_DRIVER_CAPABILITIES=graphics,compute,utility,video \\\n",
    "    \t_CUDA_COMPAT_TIMEOUT=90\n",
    "\t#echo \"Environment variables exported\"\n",
    "\techo \"Nvidia Modulus 22.07 Apptainer image\"\n",
    "```\n",
    "\n",
    "These environment variables are exported in the runtime not during the build. So, to access an environment variables during the build you need to redefine it in the `%post` section. Since this section is executed firstly in the runtime. You can put any message here which you want to print at each startup. Here I am printing \"Nvidia Modulus 22.07 Apptainer image\".\n",
    "\n",
    "### Copy files to the image\n",
    "\n",
    "```sh\n",
    "# Copy required files    \t\n",
    "%files\n",
    "\tmodulus/pyproject.toml ./\n",
    "\tmodulus/poetry.lock ./\n",
    "\tmodulus/. /modulus/\n",
    "```\n",
    "\n",
    "### Build instructions\n",
    "We put all the build instruction in this section. \n",
    "\n",
    "#### Update the base-image's OS and install dependencies using the apt package manager. Some application requires you to put interactive command such as yes/no, country name etc. The `-y` selects yes as the default choice. The `DEBIAN_FRONTEND=noninteractive` ensures that the default option is selected in fields such as country name, keyboard type etc.\n",
    "```sh\n",
    "%post\n",
    "\t# At this point I gave up with their useless $APPTAINER_ENVIRONMENT\n",
    "\t# echo \"export POETRY_VERSION=1.1.13\" >> $APPTAINER_ENVIRONMENT\n",
    "\t# Setup git lfs, graphviz gl1(vtk dep)\n",
    "\techo \"Updating the OS\"\n",
    "\tapt-get update && DEBIAN_FRONTEND=noninteractive\\\n",
    "    \tapt-get install -y git-lfs graphviz libgl1 && \\\n",
    "    \tgit lfs install\n",
    "    pip install poetry==1.1.13\n",
    "```\n",
    "\n",
    "#### Install build esentials\n",
    "These tools are needed for building `.so` library files simialr to `.dll` in Windows.\n",
    "```sh\n",
    "    \techo \"Installing OptiX and CMake\"\n",
    "    \tcd /modulus && /modulus/NVIDIA-OptiX-SDK-7.0.0-linux64.sh --skip-license --include-subdir --prefix=/root\n",
    "    \tcd /root && wget https://github.com/Kitware/CMake/releases/download/v3.18.2/cmake-3.18.2-Linux-x86_64.tar.gz && tar xvfz cmake-3.18.2-Linux-x86_64.tar.gz\n",
    "```\n",
    "#### Install CUDA wrapper to easily configure GPUs\n",
    "```sh\n",
    "\techo \"Installing CUDA framework for Neural networks\"\n",
    "\tpip install git+https://github.com/NVlabs/tiny-cuda-nn/@master#subdirectory=bindings/torch\n",
    "```\n",
    "\n",
    "#### Install the virtual environment\n",
    "The dependencies of the Poetry managed Python virtual environment are stored in `pyproject.toml`. [This file](https://pip.pypa.io/en/stable/reference/build-system/pyproject-toml/) contains build system requirements and information, which are used by pip to build the package.\n",
    "\n",
    "Once you have finished the download `poetry.lock` stores the version of each Python package in the Poetry managed virtual environment. This prevents you from automatically getting the latest versions of your dependencies.\n",
    "\n",
    "```sh\n",
    "\tcd /modulus && poetry config virtualenvs.create false \\\n",
    "\t&& poetry install --no-interaction\n",
    "```\n",
    "\n",
    "#### Install PySDF\n",
    "This module enables the user to use the Tessellation library.\n",
    "\n",
    "```sh\n",
    "    cd /modulus/external/pysdf && python setup.py install\n",
    "    pip3 install setuptools==42.0.0 # to use easy_install\n",
    "\tpython3 -m easy_install /modulus/external/eggs/pysdf-0.1-py3.8-linux-x86_64.egg\n",
    "```\n",
    "\n",
    "#### Cleanup the image\n",
    "```sh\n",
    "\trm -rf /root/NVIDIA-OptiX-SDK-7.0.0-linux64 /root/cmake-3.18.2-Linux-x86_64 /modulus/external/pysdf  /modulus/.git*\t\n",
    "    rm -fv /modulus/setup.py /modulus/setup.cfg /modulus/MANIFEST.in\n",
    "```\n",
    "\n",
    "### Add metadata\n",
    "```sh\n",
    "%labels\n",
    "    Author Prakhar\n",
    "    Version v0.0.1\n",
    "    MyLabel Modulus 22.07 Apptainer image\n",
    "```\n",
    "\n",
    "### Add help\n",
    "```sh\n",
    "%help\n",
    "    Nvidia Modulus Apptainer container. \n",
    "```\n",
    "\n",
    "Save the file as `buildimage`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fd4c66-17c2-4319-9bbf-56dd15560bfb",
   "metadata": {},
   "source": [
    "# Build the image\n",
    "The command to build an image is:\n",
    "```sh\n",
    "apptainer build IMAGE_NAME DEFINITION_FILE\n",
    "```\n",
    "This command requires the superuser permission `sudo`. Create a new bash file `build_command.sh` with the following contents.\n",
    "\n",
    "```sh\n",
    "sudo apptainer build modulus.img buildimage >> output.txt\n",
    "```\n",
    "This will save all the outputs in `output.txt` in the `pwd`. Apptainer will still print the basic information in the terminal. Run the bash file to build the Apptainer image. The resulting image will be around 7.4GB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938b5ec5-06f9-4de9-8298-96676fbddf1f",
   "metadata": {},
   "source": [
    "# Testing the image\n",
    "Check if imports are working for `torch`, `modulus` and `pysdf.sdf`.\n",
    "\n",
    "```sh\n",
    "(base) hell@Dell-Precision-T7910:~/Desktop/apptainer/nvidia_modulus(docker_extracted)$ apptainer shell modulus.img \n",
    "Nvidia Modulus 22.07 Apptainer image\n",
    "Apptainer> python\n",
    "Python 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n",
    "[GCC 10.3.0] on linux\n",
    "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    ">>> import torch\n",
    ">>> import modulus\n",
    ">>> import pysdf.sdf\n",
    ">>> \n",
    "Apptainer> exit\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
